{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598176304015",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package stopwords to\n[nltk_data]     /home/codeseys/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /home/codeseys/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /home/codeseys/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /home/codeseys/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        ID           User                                               Text  \\\n0   864192      Carly_FTS  I *heart* filling up @dennisschaub desk   1 it...   \n1   523691  Open_Sourcing  #SocioMat - people create prettier, younger an...   \n2   584154       xxcharlx                no way i dont want the tour to end    \n3  1527961    andreapuddu  @HemalRadia Hi Amazing Brother! Sending Limitl...   \n4    28609          umbec                   @flockmaster they are chocolate    \n\n   Sentiment  \n0          1  \n1          1  \n2          0  \n3          1  \n4          1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>User</th>\n      <th>Text</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>864192</td>\n      <td>Carly_FTS</td>\n      <td>I *heart* filling up @dennisschaub desk   1 it...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>523691</td>\n      <td>Open_Sourcing</td>\n      <td>#SocioMat - people create prettier, younger an...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>584154</td>\n      <td>xxcharlx</td>\n      <td>no way i dont want the tour to end</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1527961</td>\n      <td>andreapuddu</td>\n      <td>@HemalRadia Hi Amazing Brother! Sending Limitl...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>28609</td>\n      <td>umbec</td>\n      <td>@flockmaster they are chocolate</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df_train = pd.read_csv('training_data.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordslist =  set(stopwords.words('english'))\n",
    "lemmatty = WordNetLemmatizer()\n",
    "wordnetmap = {\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV}\n",
    "def removestopwords(text):    \n",
    "    return \" \".join([word for word in str(text).split() if word not in stopwordslist])\n",
    "def lemmy(text):\n",
    "    pos_text = nltk.pos_tag(str(text).split())\n",
    "    return \" \".join([lemmatty.lemmatize(word,wordnetmap.get(pos[0],wordnet.NOUN))for word, pos in pos_text])    \n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+','',text)\n",
    "    text = re.sub(r'#','',text)\n",
    "    \n",
    "    text = re.sub(r'RT[\\s]+','',text)\n",
    "    text = re.sub(r'https?:\\/\\/\\S+','',text)\n",
    "    \n",
    "    text = lemmy(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]','', text)\n",
    "    text = removestopwords(text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# df_train['Text']=df_train['Text'].apply(clean_text)\n",
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "WordList(['SocioMat', 'people', 'create', 'prettier', 'younger', 'and', 'better', 'looking', 'avatars', 'of', 'themselves'])"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "TextBlob(df_train['Text'][1]).words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "xTrain: (800000,) yTrain: (800000,)\nxTest: (50000,) yTest: (50000,)\nxValidation: (150000,) yValidation: (150000,)\n"
    }
   ],
   "source": [
    "# df_train.to_csv('newcsvtest.csv')\n",
    "SEED=114\n",
    "x = df_train['Text']\n",
    "y = df_train['Sentiment']\n",
    "\n",
    "x_train, x_validation_test, y_train, y_validation_test = train_test_split(x,y,test_size=0.2,random_state=SEED)\n",
    "\n",
    "x_validation,x_test,y_validation,y_test=train_test_split(x_validation_test,y_validation_test,random_state=SEED)\n",
    "\n",
    "print(\"xTrain:\",x_train.shape,\"yTrain:\",y_train.shape)\n",
    "print(\"xTest:\",x_test.shape,\"yTest:\",y_test.shape)\n",
    "print(\"xValidation:\",x_validation.shape,\"yValidation:\",y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(50000, 317)"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(analyzer=clean_text)\n",
    "tfidfvect = tfidf.fit_transform(x_test)\n",
    "tfidfvect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "               0        1         2    3    4    5    6    7    8  ...    참  \\\n0  0.579624  0.0  0.00000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n1  0.486722  0.0  0.00000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n2  0.351588  0.0  0.35667  0.341409  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n3  0.360189  0.0  0.00000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n4  0.370298  0.0  0.00000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n\n     철    킨    테    표    하    한    해    했    회  \n0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n\n[5 rows x 317 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>...</th>\n      <th>참</th>\n      <th>철</th>\n      <th>킨</th>\n      <th>테</th>\n      <th>표</th>\n      <th>하</th>\n      <th>한</th>\n      <th>해</th>\n      <th>했</th>\n      <th>회</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.579624</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.486722</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.351588</td>\n      <td>0.0</td>\n      <td>0.35667</td>\n      <td>0.341409</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.360189</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.370298</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 317 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "ndf = pd.DataFrame(tfidfvect.toarray(),columns=tfidf.get_feature_names())\n",
    "ndf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}