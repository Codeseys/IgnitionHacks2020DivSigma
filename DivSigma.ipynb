{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598152216884",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package stopwords to\n[nltk_data]     /home/codeseys/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /home/codeseys/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /home/codeseys/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /home/codeseys/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        ID           User                                               Text  \\\n0   864192      Carly_FTS  I *heart* filling up @dennisschaub desk   1 it...   \n1   523691  Open_Sourcing  #SocioMat - people create prettier, younger an...   \n2   584154       xxcharlx                no way i dont want the tour to end    \n3  1527961    andreapuddu  @HemalRadia Hi Amazing Brother! Sending Limitl...   \n4    28609          umbec                   @flockmaster they are chocolate    \n\n   Sentiment  \n0          1  \n1          1  \n2          0  \n3          1  \n4          1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>User</th>\n      <th>Text</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>864192</td>\n      <td>Carly_FTS</td>\n      <td>I *heart* filling up @dennisschaub desk   1 it...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>523691</td>\n      <td>Open_Sourcing</td>\n      <td>#SocioMat - people create prettier, younger an...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>584154</td>\n      <td>xxcharlx</td>\n      <td>no way i dont want the tour to end</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1527961</td>\n      <td>andreapuddu</td>\n      <td>@HemalRadia Hi Amazing Brother! Sending Limitl...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>28609</td>\n      <td>umbec</td>\n      <td>@flockmaster they are chocolate</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df_train = pd.read_csv('training_data.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        ID           User                                               Text  \\\n0   864192      Carly_FTS             heart fill desk 1 mean sale amp 2 desk   \n1   523691  Open_Sourcing  sociomat people create prettier young well loo...   \n2   584154       xxcharlx                             way dont want tour end   \n3  1527961    andreapuddu  hi amazing brother sending limitless love way ...   \n4    28609          umbec                                          chocolate   \n\n   Sentiment  \n0          1  \n1          1  \n2          0  \n3          1  \n4          1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>User</th>\n      <th>Text</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>864192</td>\n      <td>Carly_FTS</td>\n      <td>heart fill desk 1 mean sale amp 2 desk</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>523691</td>\n      <td>Open_Sourcing</td>\n      <td>sociomat people create prettier young well loo...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>584154</td>\n      <td>xxcharlx</td>\n      <td>way dont want tour end</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1527961</td>\n      <td>andreapuddu</td>\n      <td>hi amazing brother sending limitless love way ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>28609</td>\n      <td>umbec</td>\n      <td>chocolate</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "stopwordslist =  set(stopwords.words('english'))\n",
    "lemmatty = WordNetLemmatizer()\n",
    "wordnetmap = {\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV}\n",
    "def removestopwords(text):    \n",
    "    return \" \".join([word for word in str(text).split() if word not in stopwordslist])\n",
    "def lemmy(text):\n",
    "    pos_text = nltk.pos_tag(str(text).split())\n",
    "    return \" \".join([lemmatty.lemmatize(word,wordnetmap.get(pos[0],wordnet.NOUN))for word, pos in pos_text])    \n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+','',text)\n",
    "    text = re.sub(r'#','',text)\n",
    "    \n",
    "    text = re.sub(r'RT[\\s]+','',text)\n",
    "    text = re.sub(r'https?:\\/\\/\\S+','',text)\n",
    "    \n",
    "    text = lemmy(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]','', text)\n",
    "    text = removestopwords(text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "df_train['Text']=df_train['Text'].apply(clean_text)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "WordList(['sociomat', 'people', 'create', 'prettier', 'young', 'well', 'look', 'avatar'])"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "TextBlob(df_train['Text'][1]).words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "xTrain: (800000,) yTrain: (800000,)\nxTest: (50000,) yTest: (50000,)\nxValidation: (150000,) yValidation: (150000,)\n"
    }
   ],
   "source": [
    "# df_train.to_csv('newcsvtest.csv')\n",
    "SEED=114\n",
    "x = df_train['Text']\n",
    "y = df_train['Sentiment']\n",
    "\n",
    "x_train, x_validation_test, y_train, y_validation_test = train_test_split(x,y,test_size=0.2,random_state=SEED)\n",
    "\n",
    "x_validation,x_test,y_validation,y_test=train_test_split(x_validation_test,y_validation_test,random_state=SEED)\n",
    "\n",
    "print(\"xTrain:\",x_train.shape,\"yTrain:\",y_train.shape)\n",
    "print(\"xTest:\",x_test.shape,\"yTest:\",y_test.shape)\n",
    "print(\"xValidation:\",x_validation.shape,\"yValidation:\",y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}